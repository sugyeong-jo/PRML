# 9.4 The EM Algorithm in General

**Goal**: Find the maximum likelihood solutions for models with latent variables.

### Step 0: Consider a probabilistic model
$$p({\bf X}, {\bf Z}|{\bf \theta})$$
- ${\bf X}$: observed variables
- ${\bf Z}$: hidden variables
- ${\bf \theta}$: a set of parameters


### Step 1: Set the likelihood function
$$p({\bf X}|{\bf \theta}) = \sum_{\bf Z}p({\bf X}, {\bf Z}|{\bf \theta}) \quad(9.69)$$
${\bf Z}$ could be continuous variables with ingegration. The goal is to maximize the likelihood function.

Due to the *Jensen's Inequality* , (9.69) is described as followed.

*Jensen's Inequality*: $E[f(x)] \ge f(E[x])$ 
$$p({\bf X}|{\bf \theta}) = \sum_{\bf Z}p({\bf X}, {\bf Z}|{\bf \theta}) \to  \ln \sum_{\bf Z}p({\bf X}, {\bf Z}|{\bf \theta}) = \ln \sum_{\bf Z} q({\bf Z}){{p({\bf X}, {\bf Z}|{\bf \theta})}\over q({\bf Z})}\ge \sum_{\bf Z} q({\bf Z}) \ln {{p({\bf X}, {\bf Z}|{\bf \theta})}\over q({\bf Z})}$$

Here, 
$$\sum_{\bf Z} q({\bf Z}) \ln {{p({\bf X}, {\bf Z}|{\bf \theta})}\over q({\bf Z})}\equiv {\mathcal L(q,\theta)} \text{ or } {\mathcal F(q,\theta)} $$

- ${\mathcal L(q,\theta)}$ : Functional 
-  ${\mathcal F(q,\theta)}$ : ?



##
Using the follow process,
$$p({\bf X}, {\bf Z}|{\bf \theta}) = {{{p({\bf X,Z,\theta}})}\over{p(\bf \theta)}}
= {{{p({\bf Z|X,\theta}})p({\bf X|\theta})p(\theta)}\over{p(\bf \theta)} } 
= {p({\bf Z|X,\theta}})p({\bf X|\theta})$$
The ${\mathcal L(q,\theta)}$ is equal as

$${\mathcal L(q,\theta)} = \sum_{\bf Z} q({\bf Z}) \ln {{p({\bf X}, {\bf Z}|{\bf \theta})}\over q({\bf Z})}= \sum_{\bf Z} q({\bf Z}) \ln {{p({\bf Z}|{\bf X, \theta})p(\bf X|\theta)}\over q({\bf Z})} \\\ 
= -\sum_{\bf Z}  q({\bf Z}) \ln {q({\bf Z})\over {{p({\bf Z}|{\bf X, \theta})}}} + \sum_{\bf Z} q({\bf Z}) \ln {{p({\bf X}|{\bf \theta})}}\\\ 
=- KL(q({\bf Z})\|p({\bf Z|X,\theta}))+\ln p({\bf X}|{\bf \theta}) $$ 

Therefore,  $p({\bf X}|{\bf \theta})\ge {\mathcal L(q,\theta)}$ and 
$$\ln p({\bf X}|{\bf \theta})={\mathcal L(q,\theta)}+KL(q\|p) \quad(9.70)$$

- ${\mathcal L(q, {\bf \theta})} = \sum_{\bf Z}q({\bf Z})\ln \left\{\frac{p({\bf X}, {\bf Z}|{\bf \theta})}{q({\bf Z})}\right\}\quad(9.71)$
 
- $KL(q\|p) = -\sum_{\bf Z} q({\bf Z}) \ln \left\{\frac{p({\bf Z}|{\bf X}, {\bf \theta})}{q({\bf Z})}\right\}\quad(9.72)$

##
The ${\mathcal F(q,\theta)}$ is equal as

$${\mathcal F(q,\theta)} = \sum_{\bf Z} q({\bf Z}) \ln {{p({\bf X}, {\bf Z}|{\bf \theta})}\over q({\bf Z})}= -\sum_{\bf Z} q({\bf Z}) \ln  q({\bf Z}) + \sum_{\bf Z} q({\bf Z})\ln {p({\bf X,Z | \theta})} \\\ 
= H(q) + \sum_{\bf Z} q({\bf Z})\ln {p({\bf X,Z | \theta})} $$

Therefore,  $p({\bf X}|{\bf \theta})\ge {\mathcal F(q,\theta)}$ and 
$$p({\bf X}|{\bf \theta})\ge\sum_{\bf Z} q({\bf Z})\ln {p({\bf X,Z | \theta})}+H(q)$$
![enter image description here](https://lh3.googleusercontent.com/4OtE8HKhX7pxDUK-0EX4i9sZBmZ_XFco3c6h3aY2n0esMggcd4mPnWovG7INWpPsJGefyjl1oLxDuHgM1AsxdR9NUpcCzy_abJbL8ppPEts9Yk5gZK44PvyDXThlT3kr5dJatt-YQuh-4wHg1kRhilOa_KIEl5AoRoNSXnbBMUm4m7Zpl4ZPleX-ofeDs07j_KsOl1S3_Tskt4eROBET_vUm37sg4PIzgzaPVA5FP42LRSuL-cqYv9p8pP7GHtFpfRTKum4nV81bNAgDm7mvImgI52HindTt8xS7PMAqUf63WqeDM-I-Gcu_LO5qrk7St89Zw1wurW2s0nIHiLkUXq4uhJTS_hgOqeMZQUTkJZ7ByfgAcQ_xe0dqMWv-2nnj1o6s_A6Bj0v2ydrufg25UR5TMytSo-YD0I1Acy5tUZ5R9bij6Z9xMQ0YzCHVitc89sFfKnf13CsWB2B-3lDwUaZdnFD93eC23eojLMtE9fwQJkTATLwcN5vPuF6HbPDyGsJSc7PA2I3EDbf3jJtVjz6Xh81eMkQx5Fby3RZp6G1wrdF2CcIyn70S4FUXdfQdyvtkyc2AGJ8occF8f7N3Iuo6M2GCB3tEha74hNNbY9uGY8vAbECgTVIvoW9TiQctNFSOLv4FgVvRDL2UMxdiXUN6DN_WCflNSlqA3FdA1FsL4SsTp2OIjw=w1577-h487-no)
##

### Step 3: (E - step) Maximize ${\mathcal L(q,\theta)}$
$$\ln p({\bf X}|{\bf \theta}) = L(q, {\bf \theta}) + KL(q\|p)$$

*(Gibb's Inequality)*:  함수 $q$와 $p$에 대해 $KL[p\|q] \ge 0$을 항상 만족함

- if $p=q \to KL[p\|q] \ge 0$, $p\ne q \to KL[p\|q] \ge 0$

- (proo) $KL[p\|q] = \sum_i p_i \ln{\frac{p_i}{q_i}} = - \sum_i p_i \ln{\frac{q_i}{p_i}}\ge -\ln[\sum_i p_i\frac{q_i}{p_i}]=-\ln[\sum_i q_i]=0$

$$\therefore{\mathcal L(q,\theta)} \text{ is a lower bound on }\ln p({\bf X}|{\bf \theta})$$

Suppose that the current value of the parameter vector is $\theta^{old}$. 
The lower bound ${\mathcal L(q,\theta^{old})}$ is maximized with respect to $q(\bf Z)$ while holding $\theta^{old}$.

The solution of $\max {\mathcal L(q,\theta^{old})}$ will occur when KL is vanished, 
$$ q^{k+1}({\bf Z}) = {p({\bf Z}|{\bf X}, {\bf \theta^{t}})}.$$
즉, 잠재변수에 대한 분포 $q({\bf Z})$가 사후분포와 동일할 때 ${\mathcal L(q,\theta^{old})}$ 가 가장 큰 값을 가지게 된다.
![enter image description here](https://lh3.googleusercontent.com/UhPqWR9SwqA4u1J_68uedNpx8ptjZZLodVNbJVMSTzULPmUrumyvirFdVkv3nOLJ2UPWQAAwkYAhqCMa-2a4J-m6Gr57CcG94cReOUqlGMvTNZqsbx9BLM5qsqEmSk2GDBO6O9qmNHee-XPPCbudPR9UjX6LdKYiSFrIacPKo6J6YrCSuO61EAmpGuVeKRsBLzwSw3johkJp7IN2-UyxAu-9cJT6dx22vzBDcqvZkjtXIwHJOgTANezi0UT8FfDXYW5yvQpmnFFwHKDJM23yVP82L83VIF3lvWljwoYecgcpWhZeRls9HbuCIKaucG-1qEheQVhgRRz1WAyDuym_wm0j3MNIQo-RZclwLpx1sUcOIXXftsP-5bg7lMD2zQMIaB9b8UJWelbsa4ZBUMCoNa3vYr93hI1qIr5_fjArudXT6ZU0RGNHTjcL4quWR8hWym05MHHj6iYP6qcUtuttaXzZB-Qd4Qe2SU9fkTsPqDY1gW75Bi6JXS8zBhQHatQtaO5_-UddzDiclKoy3zKXOROPzWm3W1GwgTWHAMtz5KrIIhLCOmxLyie7LaOf-U0AvsloHv4v1JKdFXFZiKeXnw6QlxVLUAYEldaYKdpA6K6nELcXAGe8Xm-YuWY57RcbZzbPJh-OvLVu2Xzg1IxfvPE-k0B-LQ8096g82ZMNbVpxsOGFQ0xd3Q=w1585-h515-no)

##

### Step 4: (M - step) Maximize ${\mathcal F(q,\theta)}$

The distribution $q(\bf Z)$ is held fixed and the lower bound $\mathcal L(q, θ)$ is maximized with respect to $\theta$ to give some new value $\theta^{new}$

Then the 
$$\theta ^{k+1} = \max {\mathcal F (q^{k+1},\theta)} = \max  \sum_{\bf Z} q^{k+1}({\bf Z})\ln {p({\bf X,Z | \theta})}$$
${\mathcal F(q,\theta)} =  \sum_{\bf Z} p({\bf Z}|{\bf X}, \theta^{old})\ln p({\bf X}, {\bf Z}|\theta) - \sum_{\bf Z} p({\bf Z}|{\bf X}, \theta^{old})\ln p({\bf Z}|{\bf X}, \theta^{old})\\\ = Q(\theta, \theta^{old}) + const \quad(9.74)$

![enter image description here](https://lh3.googleusercontent.com/HOSdorQeSv6bsvoczJ5g1mFx1t-PG26Q7VQ3mRQysxRcHogU1GGjegbdyR_gQ6x2JIlKjVteuK34V0ixuYMBfwUNsf1KGUwJG1GTNbZsoNxpXRrBadnmH6VvEalnvymB01M7ATUOysgJOOaXiwHyyvSkSCd3jzF-njiugrgWVywKpPHjDHPkHYwBDTEnMFBX1mSdwhnd7WXuGJIX7c1LM1oR-PUuPwBYVscTm6_-G-AbYp_Rnl8xj9ppSaW7Zh7Sl5D_OtU0o94l4Y4sffX43LnuDicfDUIBXNnCpn8PvlX9qi8hubxkKVMbu8YK5pxzJK76sUlXNDD6dJUQSIk224jcNyLVUh_bvmpqx8kDOQqf3zPWsFlSNHMs9f0SGYP4WCnbV_mAZp6Cua6kGoCt3QnkxNIJEAVhueRBcndgtOf-uTwkv-WrXwBifUbDzCywn1dfaXEPX7MBvtkaoZiBMFSgPJjll8bqMDB5AUj-qs04SmPK2RohMv61w-_X_HWqhqGjoDAbhYcO6InNlug7bjsp7KWtAoFwqspgTfG6ZlGMHimMEqpnU8EG4QUFTRJQSJtGIKnUnKJzr1j5-104cbSPX00tjjmpjpHbgtBiheCEn3w4cLeddQ6_6JYSttgXU6gQ7P-Rg33Dj9MfBMQS47Ng3aAq_Zgc3lY66_YV-7zJ2s6KCP-bvw=w1568-h642-no)

### Step5: Iteration about E-step and M-step until convergence 
##

### Sumary

![enter image description here](https://lh3.googleusercontent.com/QQKFbCAFBoe1Oafe6ub8i6buEMfbp1VzZSZDsTRd8F9tul2aORiWE2AXp8uNoDnQ7_xaN70wCmmhIZuO9wXlFhnNE-1WrtWKjnfy6BUZX3aW7VTLzyjyMbG1YSPnaZnb_wg0BrWym2Luj3blJX1iiIHlQXEDsZMmdaCadUCHuICS3E2i79zbWSmBXBrGoc1o4Bs0dZ21CzBWrto-f3LqVWF03JhWVvUOLl2pfOUdSn0PmWCpwcGOO4ghfpSfc3WP4lkCEtLYH4oSfaq1u_y-q3qk4iBPvbEmJ-kfhBcZDlFhgebN0exbHM-UXApwDIwe1t-6fFykPW8gn4os_pRptanlx-5hBV5qhub89wLOp2s84of_4O_cS8fNwa6sl7I4Pfe9LUrmsZ6hnkeTD1NbBsOYcqsSebxMzRzm_AFJbimWarg2jCc5n89NdE3Ajh6rz6gaCKEEebUyAkAKf2ydZgF_-H84Ou1v0KNsCRBnU3705tK95zxw4hBQp0R5lQ3alUCVaYhk_RZCEjyQa8LKjwaIdFvUa7V0SBlpKGhbbp8ptghxlDpqY2NCqrChhRcc_w1HypD232JV4orBiRGN7E1d8JRcoYSqDaxJFoK3mu76ZGoOqYtfeVRUQHppBeYPBIyJW7Yk0mruX-oPgnEZEKoXzovb5cow2cIkh-e8OFK0bDmewxvsKA=w1572-h586-no)
**E-step**: the posterior probability that is evaluated in the E step
$$p({\bf Z}|{\bf X}, \theta) = \frac{p({\bf X}, {\bf Z}|\theta)}{\sum_{\bf Z}p({\bf X
}, {\bf Z}|\theta)}=\frac{\prod_{n=1}^N p({\bf x}_n, {\bf z}_n|\theta)}{\sum_{\bf Z}\prod_{n=1}^N p({\bf x}_n, {\bf z}_n|\theta)}=\prod_{n=1}^N p({\bf z}_n|{\bf x}_n, \theta)\quad(9.75)$$


**M-step**
$${\bf \mu}_k^{new} = {\bf \mu}_k^{old} + \left(\frac{\gamma^{new}(z_{mk})-\gamma^{old}(z_{mk})}{N_k^{new}}\right)({\bf x}_n-{\bf \mu}_k^{old})\quad(9.78)$$
$$N_k^{new} = N_k^{old} + \gamma^{new}(z_{mk}) - \gamma^{old}(z_{mk})\quad(9.79)$$


